{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for machine learning\n",
    "This notebook is designed to preprocess  neuroimaging and behavioral data for machine learning analyses. This includes mean-centering and normalizing vector data (i.e. questionnaire scores, demographics) and extracting a beta series from the fMRI data. The beta series is a result of deconvolving the time series for each trial which allows us to use the beta maps as entries for classification rather than a BOLD timeseries (see Mumford 2012 for a more thorough explanation of this; these steps are also outlined below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, Series, read_csv\n",
    "\n",
    "# Study specific variables\n",
    "study_home = '/home/camachocm2/Analysis/KidVid_MVPA'\n",
    "sub_data_file = study_home + '/doc/subjectinfo.csv'\n",
    "\n",
    "subject_info = read_csv(sub_data_file)\n",
    "subjects_list = subject_info['subjID'].tolist()\n",
    "version = subject_info['version'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fMRI data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "from nipype.interfaces.fsl.utils import Merge, ImageMeants, Split, MotionOutliers\n",
    "from nipype.algorithms.modelgen import SpecifyModel\n",
    "from nipype.interfaces.nipy.model import FitGLM, EstimateContrast\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, DataGrabber\n",
    "from nipype.interfaces.fsl.model import GLM, Level1Design, FEATModel\n",
    "from nipype.interfaces.nipy.preprocess import Trim\n",
    "\n",
    "\n",
    "preproc_fmri = study_home + '/processed_data'\n",
    "output_dir = study_home + '/analysis/preproc'\n",
    "timing_dir = study_home + '/timing'\n",
    "workflow_dir = study_home + '/workflows'\n",
    "\n",
    "TR=2 #in seconds\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling nodes\n",
    "infosource = Node(IdentityInterface(fields=['subjid','version']), \n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list),('version', version)]\n",
    "infosource.synchronize = True\n",
    "\n",
    "template = {'proc_func': preproc_fmri + '/{subjid}/preproc_func.nii.gz', \n",
    "            'raw_func': preproc_fmri + '/{subjid}/raw_func.nii.gz', \n",
    "            'timing':timing_dir + '/{version}.txt'}\n",
    "selectfiles = Node(SelectFiles(template), name='selectfiles')\n",
    "\n",
    "substitutions = [('_subjid_', ''),\n",
    "                 ('_version_version1',''), \n",
    "                 ('_version_version2',''), \n",
    "                 ('_version_version3','')]\n",
    "datasink = Node(DataSink(substitutions=substitutions, \n",
    "                         base_directory=output_dir,\n",
    "                         container=output_dir), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract timing for Beta Series Method- mark trials as high and low motion\n",
    "def pull_timing(timing_file,motion_file):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from pandas import DataFrame,Series,read_table\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    \n",
    "    timing = read_table(timing_file)\n",
    "    motion_series = read_table(motion_file, header=None, names=['fd'])\n",
    "    motion = motion_series['fd'].tolist()\n",
    "    \n",
    "    names = timing['Condition'].tolist()\n",
    "    cond_names = [names[a] + str(a) for a in range(0,len(names))]\n",
    "    print(cond_names)\n",
    "    onsets = []\n",
    "    for a in timing['Onset'].tolist():\n",
    "        onsets.append([a])\n",
    "\n",
    "    durations = []\n",
    "    for b in timing['Duration'].tolist():\n",
    "        durations.append([b])\n",
    "    \n",
    "    #make bunch file\n",
    "    timing_bunch = []\n",
    "    timing_bunch.insert(0,Bunch(conditions=cond_names,\n",
    "                                onsets=onsets,\n",
    "                                durations=durations,\n",
    "                                amplitudes=None,\n",
    "                                tmod=None,\n",
    "                                pmod=None,\n",
    "                                regressor_names=['fd'],\n",
    "                                regressors=[motion]))\n",
    "    return(timing_bunch)\n",
    "\n",
    "# Function to create contrast lists from a bunch file\n",
    "def beta_contrasts(timing_bunch):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from nipype.interfaces.base import Bunch\n",
    "    from numpy import zeros\n",
    "    \n",
    "    conditions_names = timing_bunch[0].conditions\n",
    "    \n",
    "    # Make the contrast vectors for each trial\n",
    "    boolean_con_lists = []\n",
    "    num_cons = len(conditions_names)\n",
    "    for i in range(0,num_cons):\n",
    "        boo = zeros(num_cons)\n",
    "        boo[i] = 1\n",
    "        boolean_con_lists.append(list(boo))\n",
    "    \n",
    "    # Create the list of lists for the full contrast info\n",
    "    contrasts_list = []\n",
    "    for a in range(0,num_cons):\n",
    "        con = (conditions_names[a], 'T', conditions_names, boolean_con_lists[a])\n",
    "        contrasts_list.append(con)\n",
    "    \n",
    "    return(contrasts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get framewise displacement to use as a regressor in the GLM\n",
    "get_fd = Node(MotionOutliers(metric='fd',\n",
    "                             out_metric_values='FD.txt', \n",
    "                             out_metric_plot='FD.png'),\n",
    "              name='get_fd')\n",
    "\n",
    "# Extract timing\n",
    "pull_timing = Node(Function(input_names=['timing_file','motion_file'],\n",
    "                            output_names=['timing_bunch'],\n",
    "                            function=pull_timing), \n",
    "                   name='pull_timing')\n",
    "\n",
    "# create the list of T-contrasts\n",
    "define_contrasts = Node(Function(input_names=['timing_bunch'], \n",
    "                                 output_names = ['contrasts_list'], \n",
    "                                 function=beta_contrasts),\n",
    "                        name = 'define_contrasts')\n",
    "\n",
    "# Specify FSL model - input bunch file called subject_info\n",
    "modelspec = Node(SpecifyModel(time_repetition=TR, \n",
    "                              input_units='secs',\n",
    "                              high_pass_filter_cutoff=128),\n",
    "                 name='modelspec')\n",
    "\n",
    "# Generate a level 1 design\n",
    "level1design = Node(Level1Design(bases={'dgamma':{'derivs': False}},\n",
    "                                 interscan_interval=TR, \n",
    "                                 model_serial_correlations=True), \n",
    "                    name='level1design')\n",
    "\n",
    "# Estimate Level 1\n",
    "generate_model = Node(FEATModel(), \n",
    "                      name='generate_model')\n",
    "\n",
    "# Run GLM\n",
    "extract_pes = Node(GLM(out_file = 'betas.nii.gz'), \n",
    "                   name='extract_pes')\n",
    "\n",
    "# Trim the nuissance regressor from the betas (the motion regressor)\n",
    "trim_pes = Node(Trim(end_index = 24, out_file='betas.nii.gz'), \n",
    "                name='trim_pes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocflow = Workflow(name='preprocflow')\n",
    "preprocflow.connect([(infosource, selectfiles,[('subjid','subjid')]),\n",
    "                     (infosource, selectfiles,[('version','version')]),\n",
    "                     (selectfiles, get_fd, [('raw_func','in_file')]),\n",
    "                     (selectfiles, pull_timing, [('timing','timing_file')]),\n",
    "                     (selectfiles, modelspec, [('proc_func','functional_runs')]),\n",
    "                     (get_fd, pull_timing, [('out_metric_values','motion_file')]),\n",
    "                     (pull_timing, modelspec, [('timing_bunch','subject_info')]),\n",
    "                     (pull_timing, define_contrasts, [('timing_bunch','timing_bunch')]),\n",
    "                     (define_contrasts, level1design, [('contrasts_list','contrasts')]),\n",
    "                     (modelspec, level1design, [('session_info','session_info')]),\n",
    "                     (level1design,generate_model, [('ev_files','ev_files')]),\n",
    "                     (level1design,generate_model, [('fsf_files','fsf_file')]),\n",
    "                     (generate_model,extract_pes, [('design_file','design')]),\n",
    "                     (generate_model,extract_pes, [('con_file','contrasts')]),\n",
    "                     (selectfiles,extract_pes, [('proc_func','in_file')]),\n",
    "                     (extract_pes, trim_pes, [('out_file','in_file')]),\n",
    "                     \n",
    "                     (trim_pes,datasink,[('out_file','betas')]),\n",
    "                     (get_fd, datasink, [('out_metric_values','fd_motion')]),\n",
    "                     (get_fd, datasink, [('out_metric_plot','fd_motion_plots')]),\n",
    "                     (generate_model,datasink,[('design_image','design_image')])\n",
    "                    ])\n",
    "preprocflow.base_dir = workflow_dir\n",
    "preprocflow.write_graph(graph2use='flat')\n",
    "preprocflow.run('MultiProc', plugin_args={'n_procs': 4,'memory_gb':10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questionnaire/Demographic data preprocessing\n",
    "These cells standardize the features of interest that are not neuroimaging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBCL_intern</th>\n",
       "      <th>CBCL_extern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CBCL_intern  CBCL_extern\n",
       "0          NaN          NaN\n",
       "1          NaN          NaN\n",
       "2          NaN          NaN\n",
       "3          NaN          NaN\n",
       "4          NaN          NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import sample data\n",
    "from pandas import DataFrame, Series, read_csv, concat, notnull\n",
    "\n",
    "# isolate variables to preprocess\n",
    "vois = DataFrame(index=subject_info.index)\n",
    "vois = concat([subject_info['CBCL_intern'],subject_info['CBCL_extern']],axis=1)\n",
    "vois.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBCL_intern_std</th>\n",
       "      <th>CBCL_extern_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.152944</td>\n",
       "      <td>0.762070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.301015</td>\n",
       "      <td>-0.882686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.130629</td>\n",
       "      <td>-0.882686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.891686</td>\n",
       "      <td>0.433119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.210142</td>\n",
       "      <td>-0.553734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CBCL_intern_std  CBCL_extern_std\n",
       "21         1.152944         0.762070\n",
       "22         0.301015        -0.882686\n",
       "23         0.130629        -0.882686\n",
       "24        -0.891686         0.433119\n",
       "25        -0.210142        -0.553734"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "\n",
    "orig_vois_df = vois\n",
    "\n",
    "#first remove rows with NaNs based on column 0\n",
    "to_remove = vois[vois.columns[0]].notna()\n",
    "to_remove = to_remove[to_remove==False].index\n",
    "vois.drop(to_remove, axis=0, inplace=True)\n",
    "vois.head()\n",
    "## Next standardize each variable\n",
    "std.fit(vois)\n",
    "vois_data = std.fit_transform(vois)\n",
    "labels = []\n",
    "for a in vois.columns:\n",
    "    labels.append(a + '_std')\n",
    "std_vois_data = DataFrame(data=vois_data,columns=labels, index=vois.index)\n",
    "std_vois_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot the distributions\n",
    "import matplotlib.pyplot as plt\n",
    "std_vois_data.hist(bins=10, figsize=(10,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add the standardized values to the previous dataframe and save.\n",
    "combined_sub_info = subject_info.join(std_vois_data)\n",
    "combined_sub_info.head()\n",
    "\n",
    "combined_sub_info.to_csv(sub_data_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

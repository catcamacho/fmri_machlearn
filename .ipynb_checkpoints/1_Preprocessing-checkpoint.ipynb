{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for machine learning\n",
    "This notebook is designed to preprocess  neuroimaging and behavioral data for machine learning analyses. This includes mean-centering and normalizing vector data (i.e. questionnaire scores, demographics) and extracting a beta series from the fMRI data. The beta series is a result of deconvolving the time series for each trial which allows us to use the beta maps as entries for classification rather than a BOLD timeseries (see Mumford 2012 for a more thorough explanation of this; these steps are also outlined below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, Series, read_csv\n",
    "\n",
    "# Study specific variables\n",
    "study_home = '/home/camachocm2/Analysis/KidVid_MVPA'\n",
    "\n",
    "subject_info = read_csv(study_home + '/doc/subjectinfo.csv')\n",
    "subjects_list = subject_info['subjID'].tolist()\n",
    "version = subject_info['version'].tolist()\n",
    "\n",
    "subjects_list = [subjects_list[0]]\n",
    "version=[version[0]]\n",
    "\n",
    "print(subjects_list)\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fMRI data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "from nipype.interfaces.fsl.utils import Merge, ImageMeants, Split, MotionOutliers\n",
    "from nipype.algorithms.modelgen import SpecifyModel\n",
    "from nipype.interfaces.nipy.model import FitGLM, EstimateContrast\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, DataGrabber\n",
    "from nipype.interfaces.fsl.model import GLM, Level1Design, FEATModel\n",
    "\n",
    "preproc_fmri = study_home + '/processed_data'\n",
    "output_dir = study_home + '/analysis/preproc'\n",
    "timing_dir = study_home + '/timing'\n",
    "workflow_dir = study_home + '/workflows'\n",
    "TR=2 #in seconds\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI_GZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling nodes\n",
    "infosource = Node(IdentityInterface(fields=['subjid','version']), \n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list),('version', version)]\n",
    "infosource.synchronize = True\n",
    "\n",
    "template = {'proc_func': preproc_fmri + '/{subjid}/preproc_func.nii.gz', \n",
    "            'raw_func': preproc_fmri + '/{subjid}/raw_func.nii.gz', \n",
    "            'timing':timing_dir + '/{version}.txt'}\n",
    "selectfiles = Node(SelectFiles(template), name='selectfiles')\n",
    "\n",
    "substitutions = [('_subjid_', ''),\n",
    "                 ('_version_','')]\n",
    "datasink = Node(DataSink(substitutions=substitutions, \n",
    "                         base_directory=output_dir,\n",
    "                         container=output_dir), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract timing for Beta Series Method- mark trials as high and low motion\n",
    "def pull_timing(timing_file,motion_file):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from pandas import DataFrame,Series,read_table\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    \n",
    "    timing = read_table(timing_file)\n",
    "    motion_series = read_table(motion_file, header=None, names=['fd'])\n",
    "    motion = motion_series['fd'].tolist()\n",
    "    \n",
    "    cond_names = timing['Condition'].tolist()\n",
    "    onsets = []\n",
    "    for a in timing['Onset'].tolist():\n",
    "        onsets.append([a])\n",
    "\n",
    "    durations = []\n",
    "    for b in timing['Duration'].tolist():\n",
    "        durations.append([b])\n",
    "    \n",
    "    #make bunch file\n",
    "    timing_bunch = []\n",
    "    timing_bunch.insert(0,Bunch(conditions=cond_names,\n",
    "                                onsets=onsets,\n",
    "                                durations=durations,\n",
    "                                amplitudes=None,\n",
    "                                tmod=None,\n",
    "                                pmod=None,\n",
    "                                regressor_names=['fd'],\n",
    "                                regressors=[motion]))\n",
    "    return(timing_bunch)\n",
    "\n",
    "# Function to create contrast lists from a bunch file\n",
    "def beta_contrasts(timing_bunch):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from nipype.interfaces.base import Bunch\n",
    "    from numpy import zeros\n",
    "    \n",
    "    conditions_names = timing_bunch[0].conditions\n",
    "    \n",
    "    # Make the contrast vectors for each trial\n",
    "    boolean_con_lists = []\n",
    "    num_cons = len(conditions_names)\n",
    "    for i in range(0,num_cons):\n",
    "        boo = zeros(num_cons)\n",
    "        boo[i] = 1\n",
    "        boolean_con_lists.append(list(boo))\n",
    "    \n",
    "    # Create the list of lists for the full contrast info\n",
    "    contrasts_list = []\n",
    "    for a in range(0,num_cons):\n",
    "        con = (conditions_names[a], 'T', conditions_names, boolean_con_lists[a])\n",
    "        contrasts_list.append(con)\n",
    "        \n",
    "    return(contrasts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get framewise displacement to use as a regressor in the GLM\n",
    "get_fd = Node(MotionOutliers(metric='fd',\n",
    "                             out_metric_values='FD.txt', \n",
    "                             out_metric_plot='FD.png'),\n",
    "              name='get_fd')\n",
    "\n",
    "# Extract timing\n",
    "pull_timing = Node(Function(input_names=['timing_file','motion_file'],\n",
    "                            output_names=['timing_bunch'],\n",
    "                            function=pull_timing), \n",
    "                   name='pull_timing')\n",
    "\n",
    "# create the list of T-contrasts\n",
    "define_contrasts = Node(Function(input_names=['timing_bunch'], \n",
    "                                 output_names = ['contrasts_list'], \n",
    "                                 function=beta_contrasts),\n",
    "                        name = 'define_contrasts')\n",
    "\n",
    "# Specify FSL model - input bunch file called subject_info\n",
    "modelspec = Node(SpecifyModel(time_repetition=TR, \n",
    "                              input_units='secs',\n",
    "                              high_pass_filter_cutoff=128),\n",
    "                 name='modelspec')\n",
    "\n",
    "# Generate a level 1 design\n",
    "level1design = Node(Level1Design(bases={'dgamma':{'derivs': False}},\n",
    "                                 interscan_interval=TR, \n",
    "                                 model_serial_correlations=True), \n",
    "                    name='level1design')\n",
    "\n",
    "# Estimate Level 1\n",
    "generate_model = Node(FEATModel(), \n",
    "                      name='generate_model')\n",
    "\n",
    "# Run GLM\n",
    "extract_pes = Node(GLM(out_file = 'betas.nii.gz'), \n",
    "                   name='extract_pes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocflow = Workflow(name='preprocflow')\n",
    "preprocflow.connect([(infosource, selectfiles,[('subjid','subjid')]),\n",
    "                     (infosource, selectfiles,[('version','version')]),\n",
    "                     (selectfiles, get_fd, [('raw_func','in_file')]),\n",
    "                     (selectfiles, pull_timing, [('timing','timing_file')]),\n",
    "                     (selectfiles, modelspec, [('proc_func','functional_runs')]),\n",
    "                     (get_fd, pull_timing, [('out_metric_values','motion_file')]),\n",
    "                     (pull_timing, modelspec, [('timing_bunch','subject_info')]),\n",
    "                     (pull_timing, define_contrasts, [('timing_bunch','timing_bunch')]),\n",
    "                     (define_contrasts, level1design, [('contrasts_list','contrasts')]),\n",
    "                     (modelspec, level1design, [('session_info','session_info')]),\n",
    "                     (level1design,generate_model, [('ev_files','ev_files')]),\n",
    "                     (level1design,generate_model, [('fsf_files','fsf_file')]),\n",
    "                     (generate_model,extract_pes, [('design_file','design')]),\n",
    "                     (generate_model,extract_pes, [('con_file','contrasts')]),\n",
    "                     (selectfiles,extract_pes, [('proc_func','in_file')]),\n",
    "                     \n",
    "                     (extract_pes,datasink,[('out_cope','copes')]),\n",
    "                     (extract_pes,datasink,[('out_file','betas')]),\n",
    "                     (get_fd, datasink, [('out_metric_values','fd_motion')]),\n",
    "                     (get_fd, datasink, [('out_metric_plot','fd_motion_plots')]),\n",
    "                     (generate_model,datasink,[('design_image','design_image')])\n",
    "                    ])\n",
    "preprocflow.base_dir = workflow_dir\n",
    "preprocflow.write_graph(graph2use='flat')\n",
    "preprocflow.run('MultiProc', plugin_args={'n_procs': 6,'memory_gb':16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "text='/moochie/Cat/KIDVID_MVPA/KIDVID/data/C2001/emotion_processing/rp_aC2001_emotion.txt'\n",
    "motion = loadtxt(text)\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(motion)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
